{
 "metadata": {
  "name": "",
  "signature": "sha256:2999ef7aec481da5382e2026f64ff4d8aca06a493947ea5c34fbb5321f44475b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import csv\n",
      "df = pd.read_csv('sextweetstext.csv')\n",
      "tweets = df.text\n",
      "df.to_csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "<bound method DataFrame.to_csv of       Unnamed: 0                                               text  \\\n",
        "0            NaN                             S.O.S = Sleep Over Sex   \n",
        "1            NaN              @iChokeRocks yea he is officially gay   \n",
        "2            NaN                       No Condom No Sex be my Motto   \n",
        "3            NaN                                   Sex = fight over   \n",
        "4            NaN                Gunna deny me sex lol #BitchSwereve   \n",
        "5            NaN                    Sex sex sex sex sex sex sex sex   \n",
        "6            NaN  My class about Anne Frank has suddenly turned ...   \n",
        "7            NaN  why do boys want sex so fucking bad? shits not...   \n",
        "8            NaN  @Kollsvein Personal time. Sex in general would...   \n",
        "9            NaN  Fuck everything that happens in the morning if...   \n",
        "10           NaN  @OscarBeWavyy I cum ot at 10.. U cn find me at...   \n",
        "11           NaN  maria asking me for sex from daddy #knowme lma...   \n",
        "12           NaN  I'm at Gay Wad House (Milwaukee, WI) http://t....   \n",
        "13           NaN                                      Sex is fun :D   \n",
        "14           NaN  Might miss Mindset because of an unexpected ga...   \n",
        "15           NaN              Sex ain't better than love #waitwhat?   \n",
        "16           NaN                          @AndrewCasilas im not gay   \n",
        "17           NaN  @jswagg453 @tyabercrombie it's sex appeal lol ...   \n",
        "18           NaN  wonder if i can get a candle light dinner &amp...   \n",
        "19           NaN  @BeatzProducer why lease the beat when u could...   \n",
        "20           NaN  Oomf is a big a freak on god me in her just al...   \n",
        "21           NaN  @MollyDeener23 or when he doesn't lower colleg...   \n",
        "22           NaN  But even if I am a republican I am happy that ...   \n",
        "23           NaN  Im glad some states passed same-sex marriage, ...   \n",
        "24           NaN  @ryanspletzer but people will also be pissed W...   \n",
        "25           NaN       Anyone down for some victory sex? #Obama2012   \n",
        "26           NaN  Washington legalized same-sex marriage.. I am ...   \n",
        "27           NaN  Yasssssss!!!!! The gays win in Maryland!!!! I ...   \n",
        "28           NaN  Obama reelected. Dems retain Senate control. M...   \n",
        "29           NaN  @destinyyreyna the bible also says not to have...   \n",
        "...          ...                                                ...   \n",
        "8510         NaN            Did that scene just happen? Holy sex \ud83d\ude0d   \n",
        "8511         NaN                                 RT if you love sex   \n",
        "8512         NaN  I'm watching south park why everyone else cums...   \n",
        "8513         NaN  Tha Fact Dat FX Is Showinq Dem Have Sex &gt;&g...   \n",
        "8514         NaN                  @LicMi_BellyRing I mite cum up da   \n",
        "8515         NaN      @BByers26 @RobsCons likes cum in his eyeballs   \n",
        "8516         NaN  \u201c@whitney_lynn3: @TP_Mane you're gay :)\u201d http:...   \n",
        "8517         NaN  Gay-rights organization names new executive di...   \n",
        "8518         NaN  Wy They In Class Talking Bout People Sexing An...   \n",
        "8519         NaN  I am glad @I_Muff_Dive69 and @BkayP_  enjoy my...   \n",
        "8520         NaN  did @megankohman just get sold into the sex tr...   \n",
        "8521         NaN  @quasiclams she fuck me nigga untill she bleed...   \n",
        "8522         NaN  Damn My Black In Justice Diaper Bag Owell Curb...   \n",
        "8523         NaN                       The twilight sex scene #woah   \n",
        "8524         NaN  \u201c@Thomasj_28: Girls are so lazy during sex\u201d wr...   \n",
        "8525         NaN  @She_Wants_The_G on the dl I'm being kinda pat...   \n",
        "8526         NaN        @__SuchALadyyy Naw I Made Da Freaks Cum Out   \n",
        "8527         NaN  A good relationship needs at least 5 ingredien...   \n",
        "8528         NaN  Ohhh let's take about sex came on!!! Wooooowoo...   \n",
        "8529         NaN           When I do have sex it will be with my bf   \n",
        "8530         NaN  Walking around the gay capital of the united s...   \n",
        "8531         NaN              #TopSongsIDHaveSexTo Sex- Chris Brown   \n",
        "8532         NaN  @FittedN_SnapBKs me too so wen u find a spot c...   \n",
        "8533         NaN  Withholding sex from your man as punishment me...   \n",
        "8534         NaN          Protect the unprotected, sex the unsexed,   \n",
        "8535         NaN  Thanks @MrRPMurphy for taking away the best an...   \n",
        "8536         NaN  @raaaaaaaaachelZ Bitch, I'm gonna throw a sex ...   \n",
        "8537         NaN  My mom said she's not driving me anywhere this...   \n",
        "8538         NaN                                  @SIRtheKID is gay   \n",
        "8539         NaN  I hate when in a relationship a girl gives the...   \n",
        "\n",
        "      Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  \\\n",
        "0            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "1            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "2            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "3            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "4            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "5            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "6            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "7            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "9            NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "10           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "11           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "12           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "13           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "14           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "15           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "16           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "17           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "18           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "19           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "20           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "21           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "22           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "23           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "24           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "25           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "26           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "27           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "28           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "29           NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "...          ...         ...         ...         ...         ...         ...   \n",
        "8510         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8511         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8512         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8513         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8514         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8515         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8516         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8517         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8518         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8519         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8520         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8521         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8522         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8523         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8524         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8525         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8526         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8527         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8528         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8529         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8530         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8531         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8532         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8533         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8534         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8535         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8536         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8537         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8538         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "8539         NaN         NaN         NaN         NaN         NaN         NaN   \n",
        "\n",
        "      Unnamed: 8  \n",
        "0            NaN  \n",
        "1            NaN  \n",
        "2            NaN  \n",
        "3            NaN  \n",
        "4            NaN  \n",
        "5            NaN  \n",
        "6            NaN  \n",
        "7            NaN  \n",
        "8            NaN  \n",
        "9            NaN  \n",
        "10           NaN  \n",
        "11           NaN  \n",
        "12           NaN  \n",
        "13           NaN  \n",
        "14           NaN  \n",
        "15           NaN  \n",
        "16           NaN  \n",
        "17           NaN  \n",
        "18           NaN  \n",
        "19           NaN  \n",
        "20           NaN  \n",
        "21           NaN  \n",
        "22           NaN  \n",
        "23           NaN  \n",
        "24           NaN  \n",
        "25           NaN  \n",
        "26           NaN  \n",
        "27           NaN  \n",
        "28           NaN  \n",
        "29           NaN  \n",
        "...          ...  \n",
        "8510         NaN  \n",
        "8511         NaN  \n",
        "8512         NaN  \n",
        "8513         NaN  \n",
        "8514         NaN  \n",
        "8515         NaN  \n",
        "8516         NaN  \n",
        "8517         NaN  \n",
        "8518         NaN  \n",
        "8519         NaN  \n",
        "8520         NaN  \n",
        "8521         NaN  \n",
        "8522         NaN  \n",
        "8523         NaN  \n",
        "8524         NaN  \n",
        "8525         NaN  \n",
        "8526         NaN  \n",
        "8527         NaN  \n",
        "8528         NaN  \n",
        "8529         NaN  \n",
        "8530         NaN  \n",
        "8531         NaN  \n",
        "8532         NaN  \n",
        "8533         NaN  \n",
        "8534         NaN  \n",
        "8535         NaN  \n",
        "8536         NaN  \n",
        "8537         NaN  \n",
        "8538         NaN  \n",
        "8539         NaN  \n",
        "\n",
        "[8540 rows x 9 columns]>"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textblob import TextBlob\n",
      "tweetblob = TextBlob(str(tweets)).upper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetblob.sentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "Sentiment(polarity=0.18504050925925927, subjectivity=0.5666666666666668)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "counts = tweets.str.count('sex', re.IGNORECASE)\n",
      "print counts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4013.0\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "gcounts = tweets.str.count('gay', re.IGNORECASE)\n",
      "print gcounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3924.0\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "ycounts = tweets.str.count('sexy', re.IGNORECASE)\n",
      "print ycounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36.0\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "fcounts = tweets.str.count('fag', re.IGNORECASE)\n",
      "print fcounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "34.0\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "ffcounts = tweets.str.count('faggot', re.IGNORECASE)\n",
      "print ffcounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13.0\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "ccounts = tweets.str.count('cum', re.IGNORECASE)\n",
      "print ccounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "763.0\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "gtcounts = tweets.str.count('gt', re.IGNORECASE)\n",
      "print gtcounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "796.0\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "lcounts = tweets.str.count('love', re.IGNORECASE)\n",
      "print lcounts.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "543.0\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetlist = tweets.tolist()\n",
      "tweetstr = map(str, tweetlist)\n",
      "tweetstr = \"\\n\".join(tweetstr)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetstr =  unicode(tweetstr, errors='ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetstr1, tweetstr2 = tweetstr[:len(tweetstr)/2], tweetstr[len(tweetstr)/2:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "from gensim import corpora, models, similarities\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from operator import itemgetter\n",
      "import re\n",
      "\n",
      "\n",
      "\n",
      "documents = tweetstr1\n",
      "stoplist = set(stopwords.words(\"english\"))\n",
      "\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist] # len adjust\n",
      " for document in documents]\n",
      "dictionary = corpora.Dictionary(texts)\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "\n",
      "traintext = [[word for word in document.lower().split() if word not in stoplist] # len adjust\n",
      " for document in tweetstr2]\n",
      "dictionary2 = corpora.Dictionary(texts)\n",
      "corpus2 = [dictionary.doc2bow(text) for text in traintext]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus) \n",
      "corpus_tfidf = tfidf[corpus]\n",
      "train_tfidf = tfidf[corpus2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_topics = 50\n",
      "lda = models.LdaModel(train_tfidf, id2word=dictionary, num_topics=n_topics, passes=10)\n",
      "lda.update(corpus2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, n_topics):\n",
      "    temp = lda.show_topic(i, 15)\n",
      "    terms = []\n",
      "    for term in temp:\n",
      "        terms.append(term[1])\n",
      "    print \"Top 10 terms for topic #\" + str(i) + \": \"+ \", \".join(terms)\n",
      " \n",
      "print \n",
      "print 'Which LDA topic maximally describes a document?\\n'\n",
      "print 'Original document: ' + documents[1]\n",
      "print 'Preprocessed document: ' + str(texts[1])\n",
      "print 'Matrix Market format: ' + str(corpus[1])\n",
      "print 'Topic probability mixture: ' + str(lda[corpus[1]])\n",
      "print 'Maximally probable topic: topic #' + str(max(lda[corpus[1]],key=itemgetter(1))[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top 10 terms for topic #0: +, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #1: g, \\, `, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #2: h, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #3: 3, \\, (, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #4: _, (, 1, ', ,, ?, w, #, u, b, m, d, n, g, f\n",
        "Top 10 terms for topic #5: e, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #6: z, \\, (, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #7: n, \\, `, 0, 1, ', ,, ?, w, #, u, b, m, d, g\n",
        "Top 10 terms for topic #8: 2, q, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #9: v, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #10: r, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #11: b, \\, `, 0, 1, ', ,, ?, w, #, u, m, d, n, g\n",
        "Top 10 terms for topic #12: o, 7, 8, \\, g, 1, ', ,, ?, w, #, u, b, m, d\n",
        "Top 10 terms for topic #13: d, \\, `, 0, 1, ', ,, ?, w, #, u, b, m, n, g\n",
        "Top 10 terms for topic #14: n, \\, `, 0, 1, ', ,, ?, w, #, u, b, m, d, g\n",
        "Top 10 terms for topic #15: |, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #16: m, \\, `, 0, 1, ', ,, ?, w, #, u, b, d, n, g\n",
        "Top 10 terms for topic #17: !, \\, (, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #18: @, /, \\, g, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #19: f, `, 0, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #20: b, \\, `, 0, 1, ', ,, ?, w, #, u, m, d, n, g\n",
        "Top 10 terms for topic #21: ^, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #22: p, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #23: u, \\, `, 0, 1, ', ,, ?, w, #, b, m, d, n, g\n",
        "Top 10 terms for topic #24: x, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #25: y, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #26: e, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #27: 5, 6, =, \\, g, 1, ', ,, ?, w, #, u, b, m, d\n",
        "Top 10 terms for topic #28: k, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #29: ,, 0, \\, `, 1, ', ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #30: m, \\, `, 0, 1, ', ,, ?, w, #, u, b, d, n, g\n",
        "Top 10 terms for topic #31: ?, -, \\, (, 1, ', ,, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #32: w, :, (, 0, 1, ', ,, ?, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #33: \\, [, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #34: *, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #35: %, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #36: l, 9, \\, f, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #37: ., `, 0, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #38: ~, `, f, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #39: j, \", \\, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #40: c, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #41: 1, \\, `, 0, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #42: ;, \\, (, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #43: e, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #44: ], \\, f, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #45: #, \\, `, 0, 1, ', ,, ?, w, u, b, m, d, n, g\n",
        "Top 10 terms for topic #46: ), 4, $, f, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #47: ', &, \\, (, 1, ,, ?, w, #, u, b, m, d, n, g\n",
        "Top 10 terms for topic #48: o, \\, g, 0, 1, ', ,, ?, w, #, u, b, m, d, n\n",
        "Top 10 terms for topic #49: (, `, 0, 1, ', ,, ?, w, #, u, b, m, d, n, g\n",
        "\n",
        "Which LDA topic maximally describes a document?\n",
        "\n",
        "Original document: .\n",
        "Preprocessed document: [u'.']\n",
        "Matrix Market format: [(0, 1)]\n",
        "Topic probability mixture: [(37, 0.5099999999999999)]\n",
        "Maximally probable topic: topic #37\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}